#!/bin/bash
# wgs_array_merging 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() (or any entry point you may add) is
# ALWAYS executed, followed by running the entry point itself.
#
# See https://wiki.dnanexus.com/Developer-Portal for tutorials on how
# to modify this file.

main() {

    echo "Value of WGS_phased_data: '$WGS_phased_data'"
    echo "Value of array_phased_data: '$array_phased_data'"
	echo "Value of output_prefix: '$output_prefix'"

    # The following line(s) use the dx command-line tool to download your file
    # inputs to the local file system using variable names for the filenames. To
    # recover the original filenames, you can use the output of "dx describe
    # "$variable" --name".
	mkdir -p /data/

    dx download "$WGS_phased_data" -o /data/WGS_phased_data
    dx download "$array_phased_data" -o /data/array_phased_data

    # Fill in your application code here.
	
	# prepare phased array vcf for merging
	awk '/^#/{print $0;}' /data/array_phased_data \
		> /data/${output_prefix}.array.for_Merge.for_imputation.phased.vcf

	awk '/^#/{next;} NR==FNR{rs[$3]=1;ref[$3]=$4;next} $3 in rs{if($4==ref[$3] || $5==ref[$3]) print $0}' \
		/data/WGS_phased_data \
		/data/array_phased_data \
		>> /data/${output_prefix}.array.for_Merge.for_imputation.phased.vcf
	
	# prepare phased WGS vcf for merging
	awk '/^#/{print $0;}' /data/WGS_phased_data \
		> /data/${output_prefix}.wgs.for_Merge.for_imputation.phased.vcf

	awk 'BEGIN{OFS="\t"} /^#/{next;} NR==FNR{rs[$3]=1;ref[$3]=$4;alt[$3]=$5;next} 
					 $3 in rs{if($4==ref[$3] && $5==alt[$3]) {print $0}
							  if($5==ref[$3] && $4==alt[$3]) {$4=ref[$3];$5=alt[$3];
															  for(i=10;i<=NF;i++){
								  if($i=="0|1"){$i="1|0"} else if($i=="1|0") {$i="0|1"}
								  else if($i=="1|1") {$i="0|0"} else if($i=="0|0") {$i="1|1"}
							  }print $0;}}' \
		/data/${output_prefix}.array.for_Merge.for_imputation.phased.vcf \
		/data/WGS_phased_data \
		>> /data/${output_prefix}.wgs.for_Merge.for_imputation.phased.vcf
	
	# merge vcf files using bcftools
	dx-docker run --rm -v /data:/data rticode/bcftools:1.9 bcftools view \
			-Oz -o /data/${output_prefix}.array.for_Merge.for_imputation.phased.vcf.gz \
			/data/${output_prefix}.array.for_Merge.for_imputation.phased.vcf
			
	dx-docker run --rm -v /data:/data rticode/bcftools:1.9 bcftools index \
			/data/${output_prefix}.array.for_Merge.for_imputation.phased.vcf.gz
			
	dx-docker run --rm -v /data:/data rticode/bcftools:1.9 bcftools view \
			-Oz -o /data/${output_prefix}.wgs.for_Merge.for_imputation.phased.vcf.gz \
			/data/${output_prefix}.wgs.for_Merge.for_imputation.phased.vcf
			
	dx-docker run --rm -v /data:/data rticode/bcftools:1.9 bcftools index \
			/data/${output_prefix}.wgs.for_Merge.for_imputation.phased.vcf.gz

	dx-docker run --rm -v /data:/data rticode/bcftools:1.9 bcftools merge \
			-Oz -o /data/${output_prefix}.for_imputation.phased.merged.vcf.gz \
			/data/${output_prefix}.array.for_Merge.for_imputation.phased.vcf.gz \
			/data/${output_prefix}.wgs.for_Merge.for_imputation.phased.vcf.gz
	
	# check HW
	dx-docker run --rm -v /data:/data rticode/plink:1.9 plink \
		--vcf /data/${output_prefix}.for_imputation.phased.merged.vcf.gz \
		--hardy \
		--out /data/${output_prefix}.for_imputation.phased.merged.hardy 
			
	awk '$9<0.0001{print $0}' /data/${output_prefix}.for_imputation.phased.merged.hardy.hwe \
		> /data/${output_prefix}.for_imputation.phased.merged.hw_p_lt_1e-4

	# exclude
	if (( $(wc -l </data/${output_prefix}.for_imputation.phased.merged.hw_p_lt_1e-4)>0 ));then
		awk 'NR==FNR{rs[$1]=1;next} {if(!($3 in rs)) print $0}' \
			/data/${output_prefix}.for_imputation.phased.merged.hw_p_lt_1e-4 \
			<(zcat /data/${output_prefix}.for_imputation.phased.merged.vcf.gz) \
			> /data/${output_prefix}.for_imputation.phased.merged.hw_p_lt_1e-4.vcf
		gzip /data/${output_prefix}.for_imputation.phased.merged.hw_p_lt_1e-4.vcf
	else
		mv /data/${output_prefix}.for_imputation.phased.merged.vcf.gz /data/${output_prefix}.for_imputation.phased.merged.hw_p_lt_1e-4.vcf.gz
	fi		
	

		
    #
    # To report any recognized errors in the correct format in
    # $HOME/job_error.json and exit this script, you can use the
    # dx-jobutil-report-error utility as follows:
    #
    #   dx-jobutil-report-error "My error message"
    #
    # Note however that this entire bash script is executed with -e
    # when running in the cloud, so any line which returns a nonzero
    # exit code will prematurely exit the script; if no error was
    # reported in the job_error.json file, then the failure reason
    # will be AppInternalError with a generic error message.
	
	
	# The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.
    mkdir -p out/merged
    mv /data/${output_prefix}.for_imputation.phased.merged.hw_p_lt_1e-4.vcf.gz out/merged/

    dx-upload-all-outputs


}
